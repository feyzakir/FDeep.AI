import streamlit as st
from PIL import Image
from rag_pipeline import load_and_translate_documents, create_vectorstore, retrieve_relevant_chunks
from model_utils import load_model, generate_response
from llava_utils import load_llava_model, analyze_image

st.set_page_config(page_title="Dijital Pazarlama Chatbot'u", layout="wide")

st.image("FDEEP.AI.png", width=300)
st.title("ğŸ“ˆ Dijital Pazarlama ve Dijital ReklamcÄ±lÄ±k Chatbot'u ğŸ¤– ")
st.markdown("KiÅŸisel dijital pazarlama asistanÄ±nÄ±z ğŸ¤– ")

# Belge klasÃ¶rÃ¼ yolu
PDF_FOLDER = r"C:\Users\feyza\OneDrive\MasaÃ¼stÃ¼\teknofest_chatbot\dijitalpazarlama_reklamkaynaklarÄ±"

# Belgeleri yÃ¼kle ve vektÃ¶r oluÅŸtur
with st.spinner("Belgeler iÅŸleniyor..."):
    documents = load_and_translate_documents(PDF_FOLDER)
    vectorstore = create_vectorstore(documents)

# Model seÃ§imi
model_key = st.selectbox("Kullanmak istediÄŸiniz modeli seÃ§in:", ["mistral", "llama3.1.8", "qwen3", "gemma3", "deepseek-r1"])
model_name = load_model(model_key)

# ğŸ§  Chat ArayÃ¼zÃ¼
st.subheader("ğŸ’¬ Soru-Cevap (Chatbot)")
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

user_input = st.text_input("Dijital pazarlama ve dijital reklamcÄ±lÄ±k ile ilgili sorunuzu yazÄ±n:")

if st.button("GÃ¶nder"):
    if not user_input.strip():
        st.warning("LÃ¼tfen bir soru yazÄ±n.")
    else:
        relevant_docs = retrieve_relevant_chunks(vectorstore, user_input)
        context = "\n".join(relevant_docs)
        prompt = f"Belgelere dayalÄ± olarak yanÄ±t ver. Cevap TÃ¼rkÃ§e olsun ve sade bir dille yaz:\n\nKullanÄ±cÄ±nÄ±n sorusu: {user_input}\n\nÄ°lgili belgeler:\n{context}"

        with st.spinner("YanÄ±t oluÅŸturuluyor..."):
            answer = generate_response(model_name, prompt)

        st.session_state.chat_history.append(("ğŸ§‘â€ğŸ’» Soru", user_input))
        st.session_state.chat_history.append(("ğŸ¤– YanÄ±t", answer))

# Sohbet geÃ§miÅŸini gÃ¶ster
for role, msg in st.session_state.chat_history:
    st.markdown(f"*{role}:* {msg}")

# ğŸ–¼ï¸ LLaVA ile GÃ¶rsel Yorumlama
st.subheader("ğŸ–¼ï¸ GÃ¶rsel Yorumlama AsistanÄ± (LLaVA)")

uploaded_image = st.file_uploader("Bir gÃ¶rsel yÃ¼kleyin", type=["jpg", "jpeg", "png"])
question = st.text_input("GÃ¶rselle ilgili ne Ã¶ÄŸrenmek istiyorsunuz?")

if uploaded_image and question:
    with st.spinner("LLaVA modeli yÃ¼kleniyor..."):
        processor, llava_model = load_llava_model()

    image = Image.open(uploaded_image).convert("RGB")

    with st.spinner("GÃ¶rsel analiz ediliyor..."):
        output = analyze_image(processor, llava_model, image, question)
        st.image(image, caption="YÃ¼klenen GÃ¶rsel", use_column_width=True)
        st.markdown("*YanÄ±t:*")
        st.write(output)
